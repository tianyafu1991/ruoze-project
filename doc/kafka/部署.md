# 下载
```
http://archive.cloudera.com/kafka/kafka/4/
http://archive.cloudera.com/kafka/kafka/4/kafka-2.2.1-kafka4.1.0.tar.gz
```

# 部署
```
[hadoop@hadoop01 ~]$ cd ~/software/
[hadoop@hadoop01 software]$ tar -zxvf kafka-2.2.1-kafka4.1.0.tar.gz -C ~/app
[hadoop@hadoop01 software]$ cd ~/app/
[hadoop@hadoop01 app]$ ln -s kafka_2.11-2.2.1-kafka-4.1.0 kafka
[hadoop@hadoop01 app]$ cd ~/app/kafka/config/
[hadoop@hadoop01 config]$ vim server.properties
port=9092
zookeeper.connect=hadoop01:2181/kafka
log.dirs=/home/hadoop/tmp/kafka-logs

[hadoop@hadoop01 config]$ echo -e '# KAFKA ENV\nexport KAFKA_HOME=/home/hadoop/app/kafka\nexport PATH=$KAFKA_HOME/bin:$PATH' >> ~/.bashrc
[hadoop@hadoop01 config]$ source ~/.bashrc 

```

# 启动
```
[hadoop@hadoop01 ~]$ $KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties 
```

# kafka-topics.sh脚本使用
```
[hadoop@hadoop01 ~]$ kafka-topics.sh --create \
> --zookeeper hadoop01:2181/kafka \
> --partitions 3 \
> --replication-factor 1 \
> --topic ruozedata
Created topic ruozedata.

# 可以查看kafka的data 目录
[hadoop@hadoop01 ~]$ cd ~/tmp/kafka-logs/
[hadoop@hadoop01 kafka-logs]$ ll
总用量 28
-rw-rw-r--. 1 hadoop hadoop    0 9月  23 12:56 cleaner-offset-checkpoint
-rw-rw-r--. 1 hadoop hadoop    4 9月  23 13:00 log-start-offset-checkpoint
-rw-rw-r--. 1 hadoop hadoop   54 9月  23 12:56 meta.properties
-rw-rw-r--. 1 hadoop hadoop   46 9月  23 13:00 recovery-point-offset-checkpoint
-rw-rw-r--. 1 hadoop hadoop   46 9月  23 13:00 replication-offset-checkpoint
drwxrwxr-x. 2 hadoop hadoop 4096 9月  23 12:59 ruozedata-0
drwxrwxr-x. 2 hadoop hadoop 4096 9月  23 12:59 ruozedata-1
drwxrwxr-x. 2 hadoop hadoop 4096 9月  23 12:59 ruozedata-2

# 查看有哪些topic
[hadoop@hadoop01 kafka-logs]$ kafka-topics.sh --list \
> --zookeeper hadoop01:2181/kafka
ruozedata

# 查看topic的描述
[hadoop@hadoop01 kafka-logs]$ kafka-topics.sh --describe \
> --zookeeper hadoop01:2181/kafka \
> --topic ruozedata
Topic:ruozedata PartitionCount:3        ReplicationFactor:1     Configs:
        Topic: ruozedata        Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: ruozedata        Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: ruozedata        Partition: 2    Leader: 0       Replicas: 0     Isr: 0
[hadoop@hadoop01 kafka-logs]$ 
```

# 启动生产者和消费者
```
# 生产者
kafka-console-producer.sh --broker-list hadoop01:9092 --topic ruozedata
# 消费者
kafka-console-consumer.sh --bootstrap-server hadoop01:9092 --topic ruozedata
```

# 全局有序问题
```
每个partition都是独立的，单个partition是自己内部有序的
多个partition是无法保障全局有序，那么如何保障全局有序？
1.就创建一个partition
2.消费者消费的时候，分组排序 性能很低
3.一个好的做法是给需要保障有序的数据有相同的key，同一个key的数据会被写入到同一个partition中，这样就保证了有序


```

# Kafka的分区策略
```
https://github.com/apache/kafka/blob/2.2.1/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java

```

# maxwell
```
官网: http://maxwells-daemon.io/
http://maxwells-daemon.io/producers/#partitioning
producer_partition_by gives you a choice of splitting your stream by database, table, primary key, transaction id, column data, or "random"
这个参数可以让我们选择数据如何进行分区,一般都是producer_partition_by=table,一张表的变更都分到同一个分区,利用Kafka的同一个分区时自己有序的这个特性
可以解决全局乱序的问题

acks=all
max.in.flight.requests.per.connection 这个参数默认值为5 , 需要设置为1
retries 这个参数默认值为2147483647,可以设置为合适的重试次数,比如100
这两个参数详见:http://kafka.apache.org/22/documentation.html
max.in.flight.requests.per.connection:
    The maximum number of unacknowledged requests the client will send on a single connection before blocking.
    Note that if this setting is set to be greater than 1 and there are failed sends, there is a risk of message re-ordering due to retries（i.e., if retries are enabled）
这个参数如果大于1，而且开启了retries这个参数，那么可能导致数据顺序乱序
比如max.in.flight.requests.per.connection默认为5时，要插入的数据顺序为 100 200 300 400 500,在插入时 300这个数据插入失败了，而其他几个成功了
那么300会重试，然后成功了。Kafka的partition中的数据顺序就是100 200 400 500 300
所以要将max.in.flight.requests.per.connection设置为1，并开启retries，acks=all，即有1个失败就重试,且只有所有的ISR中的副本都写入成功后，这条数据才算写入成功

```

# 生产调优
## producer端调优
```
用代码开发producer时：
producer端参数：
acks=all
max.in.flight.requests.per.connection=1
retries=100
为数据设置key来保障全局有序,

用maxwell的作为producer时
要指定producer_partition_by=table,
并同步设置acks，max.in.flight.requests.per.connection，retries这3个参数

```

# 如何做数据质量校验
```
1.数据量的校验
    1.1 两边做count(1)

2.数据内容的校验
    这个一般都不太做
```